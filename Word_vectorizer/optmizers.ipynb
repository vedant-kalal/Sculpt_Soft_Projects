{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "427952ef",
   "metadata": {},
   "source": [
    "# What are Optimizers?\n",
    "\n",
    "Optimizers are algorithms used in machine learning and deep learning to adjust the parameters (weights and biases) of a model during training. Their main goal is to minimize the loss function, which measures how far the model's predictions are from the actual values. By updating the parameters in the right direction, optimizers help the model learn patterns from data and improve its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfc8154",
   "metadata": {},
   "source": [
    "## Detailed Explanation of Optimizers\n",
    "\n",
    "### 1). First Order Optimizers\n",
    "First order optimizers are optimization algorithms that use only the first derivative (gradient) of the loss function with respect to the model parameters to update those parameters. These optimizers are called \"first order\" because they rely solely on gradient information, not on higher-order derivatives (like the Hessian matrix).\n",
    "\n",
    "- **Loss Function:** A loss function (also called cost function or objective function) measures how well the model's predictions match the actual data. The goal of training is to minimize this value. Common types include:\n",
    "    - **Mean Squared Error (MSE):** Used for regression tasks, measures the average squared difference between predicted and actual values.\n",
    "    - **Cross-Entropy Loss:** Used for classification tasks, measures the difference between the predicted probability distribution and the actual distribution.\n",
    "    - **Hinge Loss:** Used for support vector machines, penalizes predictions that are on the wrong side of the margin.\n",
    "\n",
    "- **Gradient:** The gradient is a vector of partial derivatives of the loss function with respect to each model parameter. It points in the direction of the steepest increase of the loss. By moving in the opposite direction of the gradient, we can minimize the loss. Types of gradients:\n",
    "    - **Batch Gradient:** Computed using the entire dataset.\n",
    "    - **Stochastic Gradient:** Computed using a single data point.\n",
    "    - **Mini-batch Gradient:** Computed using a small subset of the data.\n",
    "\n",
    "- **Parameter Update:** The optimizer updates the model parameters by subtracting a fraction (learning rate) of the gradient from the current parameters.\n",
    "\n",
    "**Examples of First Order Optimizers:**\n",
    "- **Gradient Descent:** Updates parameters using the gradient of the loss over the whole dataset.\n",
    "- **Stochastic Gradient Descent (SGD):** Updates parameters using the gradient from a single data point at a time.\n",
    "- **Mini-batch Gradient Descent:** Uses a small batch of data for each update, balancing speed and accuracy.\n",
    "- **Momentum:** Adds a fraction of the previous update to the current update, helping to accelerate convergence and avoid local minima.\n",
    "\n",
    "### 2).  Adaptive Optimizers\n",
    "Adaptive optimizers are advanced optimization algorithms that adjust the learning rate for each parameter individually based on the history of gradients. This allows the optimizer to adapt to the geometry of the loss surface, often leading to faster and more stable convergence.\n",
    "\n",
    "- **Learning Rate:** The learning rate is a hyperparameter that determines the size of the steps taken during optimization. Adaptive optimizers automatically adjust this for each parameter.\n",
    "- **Gradient Accumulation:** Adaptive optimizers keep track of past gradients (and sometimes squared gradients) to inform future updates.\n",
    "\n",
    "**Examples of Adaptive Optimizers:**\n",
    "- **AdaGrad:** Adapts the learning rate for each parameter based on the sum of the squares of all previous gradients. Works well for sparse data.\n",
    "- **RMSProp:** Modifies AdaGrad by using a moving average of squared gradients, preventing the learning rate from shrinking too much.\n",
    "- **Adam (Adaptive Moment Estimation):** Combines the ideas of Momentum and RMSProp, using moving averages of both gradients and squared gradients.\n",
    "- **AdaDelta:** An extension of AdaGrad that seeks to reduce its aggressive, monotonically decreasing learning rate.\n",
    "\n",
    "**Key Terms Explained:**\n",
    "- **Hyperparameter:** A parameter whose value is set before the learning process begins (e.g., learning rate, batch size).\n",
    "- **Convergence:** The process of approaching a minimum value of the loss function during training.\n",
    "- **Local Minimum:** A point where the loss is lower than at neighboring points, but not necessarily the lowest possible (global minimum).\n",
    "\n",
    "By understanding these optimizers and their components, you can choose the right optimization strategy for your machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c215e77",
   "metadata": {},
   "source": [
    "# Understanding Optimizers in Machine Learning\n",
    "\n",
    "## What is an Optimizer?\n",
    "An optimizer is an algorithm or method used in machine learning and deep learning to adjust the parameters (weights and biases) of a model in order to minimize the loss function. The optimizer updates the model parameters based on the gradients computed during backpropagation, helping the model learn from data and improve its predictions.\n",
    "\n",
    "## Types of Optimizers\n",
    "\n",
    "### 1. First Order Optimizers\n",
    "First order optimizers use only the first derivative (gradient) of the loss function to update the parameters. They are generally simple and efficient.\n",
    "**Examples:**\n",
    "- Batch Gradient Descent\n",
    "- Stochastic Gradient Descent (SGD)\n",
    "- Mini-batch Gradient Descent\n",
    "\n",
    "\n",
    "### 2. Adaptive Optimizers\n",
    "Adaptive optimizers adjust the learning rate for each parameter individually based on past gradients. They often lead to faster convergence and better performance in practice.\n",
    "**Examples:**\n",
    "- AdaGrad\n",
    "- RMSProp\n",
    "- Adam\n",
    "- AdaDelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143de44a",
   "metadata": {},
   "source": [
    "# 1). First Order Optimizers\n",
    "## Batch Gradient Descent\n",
    "\n",
    "Batch Gradient Descent is an optimization algorithm used to train machine learning models. In this method, the entire training dataset is used to compute the gradient of the loss function with respect to the model parameters. The parameters are then updated based on this gradient.\n",
    "\n",
    "### How it Works:\n",
    "1. Calculate the predictions for all training examples using the current model parameters.\n",
    "2. Compute the loss (error) for all predictions compared to the actual values.\n",
    "3. Calculate the gradient (partial derivatives) of the loss function with respect to each parameter, using the entire dataset.\n",
    "4. Update the parameters by moving them in the direction that reduces the loss (opposite to the gradient).\n",
    "\n",
    "#### Characteristics:\n",
    "- Uses the whole dataset for each update, which can be slow for large datasets.\n",
    "- Provides a stable and accurate estimate of the gradient.\n",
    "- Can get stuck in local minima or saddle points.\n",
    "\n",
    "#### Formula:\n",
    "For parameter $\\theta$ and learning rate $\\alpha$:\n",
    "$$\\theta = \\theta - \\alpha \\cdot \\nabla J(\\theta)$$\n",
    "where $\\nabla J(\\theta)$ is the gradient of the loss function $J$ with respect to $\\theta$, computed over the entire dataset.\n",
    "\n",
    "#### Pros:\n",
    "- Stable convergence\n",
    "- Accurate gradient estimation\n",
    "\n",
    "#### Cons:\n",
    "- Slow for large datasets\n",
    "- High memory usage\n",
    "\n",
    "Batch Gradient Descent is best suited for smaller datasets where computation time and memory are not major concerns.\n",
    "\n",
    "### Example: Batch Gradient Descent with Epochs\n",
    "\n",
    "#### What is an Epoch?\n",
    "An **epoch** is one complete pass through the entire training dataset during the training process. In other words, when every sample in the dataset has been used once to update the model parameters, one epoch is completed. Training a model usually involves multiple epochs to allow the model to learn better from the data.\n",
    "\n",
    "###3 Example Scenario\n",
    "Suppose you have a dataset with 1000 samples. If you use batch gradient descent, the model will:\n",
    "- Use all 1000 samples to compute the gradient and update the parameters once. This is one epoch.\n",
    "- Repeat this process for several epochs (e.g., 10 epochs), so the model sees the entire dataset 10 times, updating the parameters after each pass.\n",
    "\n",
    "**Training Process:**\n",
    "1. **Epoch 1:**\n",
    "    - Compute predictions for all 1000 samples.\n",
    "    - Calculate the loss and gradients using all samples.\n",
    "    - Update the model parameters once.\n",
    "2. **Epoch 2:**\n",
    "    - Repeat the process with the updated parameters.\n",
    "3. **Continue for the desired number of epochs.**\n",
    "\n",
    "#### Why Use Multiple Epochs?\n",
    "- The model may not learn enough from just one pass through the data.\n",
    "- Multiple epochs allow the model to gradually minimize the loss and improve accuracy.\n",
    "\n",
    "#### Visualization:\n",
    "\n",
    "| Epoch | Loss (Example) |\n",
    "|-------|---------------|\n",
    "|   1   |     0.95      |\n",
    "|   2   |     0.80      |\n",
    "|   3   |     0.65      |\n",
    "|  ...  |     ...       |\n",
    "|  10   |     0.20      |\n",
    "\n",
    "As the number of epochs increases, the loss typically decreases, showing that the model is learning from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1604f4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(nb_epochs):\n",
    "    params_grad=evaluate_gradient(loss_function,data,params)\n",
    "    params=params-learning_rate * params_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af871b4f",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent (SGD)\n",
    "\n",
    "Stochastic Gradient Descent (SGD) is an optimization algorithm used to train machine learning models. Unlike batch gradient descent, which uses the entire dataset to compute the gradient, SGD updates the model parameters using only a single randomly selected data point at each step.\n",
    "\n",
    "#### How it Works:\n",
    "1. Shuffle the training dataset.\n",
    "2. For each training example:\n",
    "    - Compute the prediction using the current model parameters.\n",
    "    - Calculate the loss for this single example.\n",
    "    - Compute the gradient of the loss with respect to the model parameters (using only this example).\n",
    "    - Update the parameters immediately based on this gradient.\n",
    "3. Repeat the process for multiple epochs (passes through the dataset).\n",
    "\n",
    "#### Characteristics:\n",
    "- Updates parameters more frequently (after each example), which can lead to faster initial learning.\n",
    "- Introduces more noise in the updates, which can help escape local minima but may cause the loss to fluctuate.\n",
    "- Well-suited for large datasets and online learning.\n",
    "\n",
    "#### Formula:\n",
    "For parameter $\\theta$ and learning rate $\\alpha$, using a single example $(x_i, y_i)$:\n",
    "$$\\theta = \\theta - \\alpha \\cdot \\nabla J(\\theta; x_i, y_i)$$\n",
    "where $\\nabla J(\\theta; x_i, y_i)$ is the gradient of the loss function $J$ with respect to $\\theta$, computed for the $i$-th example.\n",
    "\n",
    "#### Example Scenario\n",
    "Suppose you have a dataset with 1000 samples. In SGD:\n",
    "- The model picks one sample at a time, computes the gradient, and updates the parameters immediately.\n",
    "- After all 1000 samples have been used once, one epoch is completed.\n",
    "- This process is repeated for several epochs (e.g., 10 epochs).\n",
    "\n",
    "**Training Process:**\n",
    "1. **Epoch 1:**\n",
    "    - For each sample (from 1 to 1000):\n",
    "        - Compute prediction, loss, gradient, and update parameters.\n",
    "2. **Epoch 2:**\n",
    "    - Repeat the process with the updated parameters.\n",
    "3. **Continue for the desired number of epochs.**\n",
    "\n",
    "#### Visualization:\n",
    "\n",
    "| Epoch | Loss (Example) |\n",
    "|-------|---------------|\n",
    "|   1   |     1.10      |\n",
    "|   2   |     0.85      |\n",
    "|   3   |     0.70      |\n",
    "|  ...  |     ...       |\n",
    "|  10   |     0.25      |\n",
    "\n",
    "The loss may fluctuate more from step to step, but generally decreases over epochs as the model learns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e1eec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(nb_epochs):\n",
    "    np.random.shuffle(data)\n",
    "    for example in data:\n",
    "        params_grad = evaluate_gradient(loss_function, example, params)\n",
    "        params = params - learning_rate * params_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ce6bb3",
   "metadata": {},
   "source": [
    "## Mini-Batch Gradient Descent\n",
    "\n",
    "Mini-Batch Gradient Descent is an optimization algorithm that combines the advantages of both batch and stochastic gradient descent. Instead of using the entire dataset (batch) or a single data point (stochastic) to compute the gradient, it uses a small random subset of the data called a \"mini-batch.\"\n",
    "\n",
    "#### How it Works:\n",
    "1. Shuffle the training dataset.\n",
    "2. Divide the dataset into small groups called mini-batches (e.g., 32, 64, or 128 samples per mini-batch).\n",
    "3. For each mini-batch:\n",
    "    - Compute predictions for all samples in the mini-batch.\n",
    "    - Calculate the loss and gradients using only the mini-batch.\n",
    "    - Update the model parameters based on the mini-batch gradient.\n",
    "4. Repeat the process for all mini-batches in the dataset (one epoch).\n",
    "5. Repeat for multiple epochs.\n",
    "\n",
    "\n",
    "#### Characteristics:\n",
    "- Balances the efficiency and stability of batch and stochastic methods.\n",
    "- Faster convergence than batch gradient descent and less noisy than stochastic gradient descent.\n",
    "- Well-suited for large datasets and can take advantage of parallel hardware (like GPUs).\n",
    "\n",
    "#### Formula:\n",
    "For parameter $\\theta$ and learning rate $\\alpha$, using a mini-batch $B$ of $m$ samples:\n",
    "$$\\theta = \\theta - \\alpha \\cdot \\frac{1}{m} \\sum_{i \\in B} \\nabla J(\\theta; x_i, y_i)$$\n",
    "where $\\nabla J(\\theta; x_i, y_i)$ is the gradient of the loss function for the $i$-th sample in the mini-batch.\n",
    "\n",
    "#### Example Scenario\n",
    "Suppose you have a dataset with 1000 samples and choose a mini-batch size of 100:\n",
    "- The dataset is divided into 10 mini-batches (each with 100 samples).\n",
    "- For each mini-batch, compute the gradient and update the parameters.\n",
    "- After all 10 mini-batches are processed, one epoch is completed.\n",
    "- Repeat for several epochs (e.g., 10 epochs).\n",
    "\n",
    "**Training Process:**\n",
    "1. **Epoch 1:**\n",
    "    - For each mini-batch (1 to 10):\n",
    "        - Compute predictions, loss, gradient, and update parameters.\n",
    "2. **Epoch 2:**\n",
    "    - Repeat the process with updated parameters.\n",
    "3. **Continue for the desired number of epochs.**\n",
    "\n",
    "#### Visualization:\n",
    "\n",
    "| Epoch | Loss (Example) |\n",
    "|-------|---------------|\n",
    "|   1   |     0.90      |\n",
    "|   2   |     0.75      |\n",
    "|   3   |     0.60      |\n",
    "|  ...  |     ...       |\n",
    "|  10   |     0.18      |\n",
    "\n",
    "Mini-batch gradient descent is the most commonly used method in deep learning due to its efficiency and effectiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd49ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(nb_epochs):\n",
    "    np.random.shuffle(data)\n",
    "    for batch in get_batches(data, batch_size=50): # here batch_size means 50 samples\n",
    "        params_grad = evaluate_gradient(loss_function, batch, params)\n",
    "        params = params - learning_rate * params_grad   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cb239d",
   "metadata": {},
   "source": [
    "# Adagrad Optimizer: Detailed Explanation\n",
    "\n",
    "## Introduction\n",
    "Adagrad (Adaptive Gradient Algorithm) is an optimization algorithm designed to adapt the learning rate for each parameter individually, improving performance on sparse data and features. It is widely used in machine learning and deep learning for training models.\n",
    "\n",
    "---\n",
    "\n",
    "## The Core Idea\n",
    "Adagrad adapts the learning rate for each parameter based on the historical gradients. Parameters with infrequent updates get larger learning rates, while those with frequent updates get smaller learning rates.\n",
    "changes learning rates for each and every 'weight', for each and every 'hidden neurons' and for each and 'every layers', for every iterations.\n",
    "\n",
    "---\n",
    "\n",
    "## Mathematical Formulation\n",
    "Let:\n",
    "- $\\theta$ be the parameter vector.\n",
    "- $g_t$ be the gradient at time step $t$.\n",
    "- $G_t$ be the sum of the squares of the gradients up to time $t$.\n",
    "\n",
    "### 1. Accumulated Squared Gradients\n",
    "For each parameter $i$:\n",
    "\n",
    "$$\n",
    "G_{t,i} = \\sum_{\\tau=1}^{t} g_{\\tau,i}^2\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $g_{\\tau,i}$ is the gradient of the loss with respect to parameter $i$ at time $\\tau$.\n",
    "\n",
    "### 2. Parameter Update Rule\n",
    "The update for each parameter $i$ at time $t$:\n",
    "\n",
    "$$\n",
    "\\theta_{t+1,i} = \\theta_{t,i} - \\frac{\\eta}{\\sqrt{G_{t,i}} + \\epsilon} \\cdot g_{t,i}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\eta$ is the initial learning rate (a hyperparameter).\n",
    "- $\\epsilon$ is a small constant (e.g., $10^{-8}$) to prevent division by zero.\n",
    "\n",
    "---\n",
    "\n",
    "## Step-by-Step Breakdown\n",
    "1. **Compute the gradient** $g_t$ for the current mini-batch.\n",
    "2. **Accumulate squared gradients** for each parameter:\n",
    "   $$\n",
    "   G_{t,i} = G_{t-1,i} + g_{t,i}^2\n",
    "   $$\n",
    "3. **Update each parameter** using the adapted learning rate:\n",
    "   $$\n",
    "   \\theta_{t+1,i} = \\theta_{t,i} - \\frac{\\eta}{\\sqrt{G_{t,i}} + \\epsilon} \\cdot g_{t,i}\n",
    "   $$\n",
    "\n",
    "---\n",
    "\n",
    "## Subformulas\n",
    "- **Element-wise operations:** All operations are performed element-wise for each parameter.\n",
    "- **Learning rate adaptation:** The effective learning rate for parameter $i$ at time $t$ is:\n",
    "  $$\n",
    "  \\text{Effective Learning Rate}_{t,i} = \\frac{\\eta}{\\sqrt{G_{t,i}} + \\epsilon}\n",
    "  $$\n",
    "\n",
    "---\n",
    "\n",
    "## Graphical Representation\n",
    "\n",
    "### 1. Accumulated Gradient Growth\n",
    "A plot of $G_{t,i}$ (y-axis) vs. time step $t$ (x-axis) shows a monotonically increasing curve, as squared gradients are always positive.\n",
    "\n",
    "### 2. Effective Learning Rate Decay\n",
    "A plot of the effective learning rate $\\frac{\\eta}{\\sqrt{G_{t,i}} + \\epsilon}$ (y-axis) vs. time step $t$ (x-axis) shows a decaying curve, since $G_{t,i}$ increases over time.\n",
    "\n",
    "```\n",
    "Graph 1: Accumulated Squared Gradients (G_t)\n",
    "|\n",
    "|         /\n",
    "|        /\n",
    "|       /\n",
    "|      /\n",
    "|_____/____________ t\n",
    "\n",
    "Graph 2: Effective Learning Rate\n",
    "|\n",
    "|\\\n",
    "| \\\n",
    "|  \\\n",
    "|   \\\n",
    "|____\\___________ t\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Advantages\n",
    "- **Automatic learning rate adaptation** for each parameter.\n",
    "- **Works well with sparse data** (e.g., NLP, text data).\n",
    "\n",
    "## Disadvantages\n",
    "- **Aggressive, monotonically decreasing learning rate** can make the learning rate too small, causing the optimizer to stop learning before reaching the optimum.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary Table\n",
    "\n",
    "| Step                | Formula                                                      |\n",
    "|---------------------|--------------------------------------------------------------|\n",
    "| Accumulate Gradients| $G_{t,i} = G_{t-1,i} + g_{t,i}^2$                        |\n",
    "| Update Parameters   | $\\theta_{t+1,i} = \\theta_{t,i} - \\frac{\\eta}{\\sqrt{G_{t,i}} + \\epsilon} \\cdot g_{t,i}$ |\n",
    "| Effective LR        | $\\frac{\\eta}{\\sqrt{G_{t,i}} + \\epsilon}$                 |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78671295",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d687a4b8",
   "metadata": {},
   "source": [
    "# AdaDelta Optimizer: Complete Detailed Explanation\n",
    "\n",
    "## Introduction\n",
    "AdaDelta is an extension of Adagrad that seeks to reduce its aggressive, monotonically decreasing learning rate. AdaDelta adapts learning rates based on a moving window of gradient updates, rather than accumulating all past squared gradients. This allows AdaDelta to continue learning even after many updates.\n",
    "\n",
    "---\n",
    "\n",
    "## Core Idea\n",
    "AdaDelta addresses Adagrad's main limitation: the continual decay of learning rates. Instead of accumulating all past squared gradients, AdaDelta restricts the window of accumulated past gradients to a fixed size (using an exponentially decaying average). It also eliminates the need to set a default learning rate.\n",
    "\n",
    "---\n",
    "\n",
    "## Mathematical Formulation\n",
    "Let:\n",
    "- $\\theta$ be the parameter vector.\n",
    "- $g_t$ be the gradient at time step $t$.\n",
    "- $E[g^2]_t$ be the exponentially decaying average of past squared gradients.\n",
    "- $E[\\Delta\\theta^2]_t$ be the exponentially decaying average of past squared parameter updates.\n",
    "- $\\rho$ be the decay rate (typically $0.9$ or $0.95$).\n",
    "- $\\epsilon$ be a small constant for numerical stability (e.g., $10^{-6}$).\n",
    "\n",
    "### 1. Accumulate Squared Gradients (Running Average)\n",
    "\n",
    "$$\n",
    "E[g^2]_t = \\rho \\cdot E[g^2]_{t-1} + (1 - \\rho) \\cdot g_t^2\n",
    "$$\n",
    "\n",
    "- $E[g^2]_t$: Running average of squared gradients at time $t$.\n",
    "- $\\rho$: Decay rate, controls how much history is considered.\n",
    "- $g_t^2$: Element-wise square of the current gradient.\n",
    "\n",
    "### 2. Compute Update Step\n",
    "\n",
    "The update step $\\Delta\\theta_t$ is computed as:\n",
    "\n",
    "$$\n",
    "\\Delta\\theta_t = - \\frac{\\sqrt{E[\\Delta\\theta^2]_{t-1} + \\epsilon}}{\\sqrt{E[g^2]_t + \\epsilon}} \\cdot g_t\n",
    "$$\n",
    "\n",
    "- $E[\\Delta\\theta^2]_{t-1}$: Running average of squared parameter updates from the previous step.\n",
    "- $g_t$: Current gradient.\n",
    "- $\\epsilon$: Small constant for stability.\n",
    "\n",
    "### 3. Accumulate Squared Updates (Running Average)\n",
    "\n",
    "After computing $\\Delta\\theta_t$, update its running average:\n",
    "\n",
    "$$\n",
    "E[\\Delta\\theta^2]_t = \\rho \\cdot E[\\Delta\\theta^2]_{t-1} + (1 - \\rho) \\cdot (\\Delta\\theta_t)^2\n",
    "$$\n",
    "\n",
    "- $E[\\Delta\\theta^2]_t$: Running average of squared parameter updates at time $t$.\n",
    "\n",
    "### 4. Parameter Update\n",
    "\n",
    "Update the parameter:\n",
    "\n",
    "$$\n",
    "\\theta_{t+1} = \\theta_t + \\Delta\\theta_t\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Step-by-Step Breakdown\n",
    "1. **Compute the gradient** $g_t$ for the current mini-batch.\n",
    "2. **Update running average of squared gradients:**\n",
    "   $$\n",
    "   E[g^2]_t = \\rho E[g^2]_{t-1} + (1-\\rho) g_t^2\n",
    "   $$\n",
    "3. **Compute update step:**\n",
    "   $$\n",
    "   \\Delta\\theta_t = - \\frac{\\sqrt{E[\\Delta\\theta^2]_{t-1} + \\epsilon}}{\\sqrt{E[g^2]_t + \\epsilon}} g_t\n",
    "   $$\n",
    "4. **Update running average of squared updates:**\n",
    "   $$\n",
    "   E[\\Delta\\theta^2]_t = \\rho E[\\Delta\\theta^2]_{t-1} + (1-\\rho) (\\Delta\\theta_t)^2\n",
    "   $$\n",
    "5. **Update parameters:**\n",
    "   $$\n",
    "   \\theta_{t+1} = \\theta_t + \\Delta\\theta_t\n",
    "   $$\n",
    "\n",
    "---\n",
    "\n",
    "## Explanation of Terms\n",
    "- **$\\rho$ (Decay Rate):** Controls the memory of the running averages. Higher $\\rho$ means longer memory.\n",
    "- **$E[g^2]_t$:** Exponentially decaying average of squared gradients (tracks how large recent gradients have been).\n",
    "- **$E[\\Delta\\theta^2]_t$:** Exponentially decaying average of squared parameter updates (tracks how large recent updates have been).\n",
    "- **$\\epsilon$:** Prevents division by zero and stabilizes the update.\n",
    "- **$g_t$:** Gradient of the loss with respect to parameters at time $t$.\n",
    "- **$\\Delta\\theta_t$:** The actual parameter update step at time $t$.\n",
    "\n",
    "---\n",
    "\n",
    "## Graphical Representation\n",
    "\n",
    "### 1. Running Average of Squared Gradients ($E[g^2]_t$)\n",
    "A plot of $E[g^2]_t$ (y-axis) vs. time step $t$ (x-axis) shows a smooth curve that adapts to the recent magnitude of gradients.\n",
    "\n",
    "### 2. Adaptive Update Step\n",
    "A plot of $\\Delta\\theta_t$ (y-axis) vs. time step $t$ (x-axis) shows how the update step size adapts over time, depending on the ratio of running averages.\n",
    "\n",
    "```\n",
    "Graph 1: Running Average of Squared Gradients (E[g^2]_t)\n",
    "|\n",
    "|      __\n",
    "|     /  \\\n",
    "|    /    \\\n",
    "|___/______\\______ t\n",
    "\n",
    "Graph 2: Adaptive Update Step (Δθ_t)\n",
    "|\n",
    "|  /\\    /\\\n",
    "| /  \\__/  \\\n",
    "|/         \\____ t\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Advantages\n",
    "- **No need to set a default learning rate.**\n",
    "- **Adapts learning rates based on recent history.**\n",
    "- **Works well for non-stationary objectives and deep networks.**\n",
    "\n",
    "## Disadvantages\n",
    "- **Still requires tuning of $\\rho$ and $\\epsilon$.**\n",
    "- **Can be sensitive to initialization of running averages.**\n",
    "\n",
    "---\n",
    "\n",
    "## Summary Table\n",
    "| Step | Formula |\n",
    "|------|---------|\n",
    "| Running Avg. Gradients | $E[g^2]_t = \\rho E[g^2]_{t-1} + (1-\\rho) g_t^2$ |\n",
    "| Update Step | $\\Delta\\theta_t = - \\frac{\\sqrt{E[\\Delta\\theta^2]_{t-1} + \\epsilon}}{\\sqrt{E[g^2]_t + \\epsilon}} g_t$ |\n",
    "| Running Avg. Updates | $E[\\Delta\\theta^2]_t = \\rho E[\\Delta\\theta^2]_{t-1} + (1-\\rho) (\\Delta\\theta_t)^2$ |\n",
    "| Parameter Update | $\\theta_{t+1} = \\theta_t + \\Delta\\theta_t$ |\n",
    "\n",
    "---\n",
    "\n",
    "If you want a code example or matplotlib graph for AdaDelta, let me know!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790813a8",
   "metadata": {},
   "source": [
    "# Adam Optimizer: Complete Detailed Explanation\n",
    "\n",
    "## Introduction\n",
    "Adam (Adaptive Moment Estimation) is a popular optimization algorithm that combines the advantages of two other extensions of stochastic gradient descent: AdaGrad and RMSProp. Adam computes adaptive learning rates for each parameter by estimating the first (mean) and second (uncentered variance) moments of the gradients.\n",
    "\n",
    "---\n",
    "\n",
    "## Core Idea\n",
    "Adam maintains two running averages for each parameter:\n",
    "- The exponentially decaying average of past gradients (first moment, like momentum)\n",
    "- The exponentially decaying average of past squared gradients (second moment, like RMSProp)\n",
    "\n",
    "Adam also includes bias correction terms to account for the initialization of these averages at zero.\n",
    "\n",
    "---\n",
    "\n",
    "## Mathematical Formulation\n",
    "Let:\n",
    "- $\\theta$ be the parameter vector.\n",
    "- $g_t$ be the gradient at time step $t$.\n",
    "- $m_t$ be the first moment estimate (mean of gradients).\n",
    "- $v_t$ be the second moment estimate (uncentered variance of gradients).\n",
    "- $\\beta_1$ be the decay rate for the first moment (typically $0.9$).\n",
    "- $\\beta_2$ be the decay rate for the second moment (typically $0.999$).\n",
    "- $\\epsilon$ be a small constant for numerical stability (e.g., $10^{-8}$).\n",
    "- $\\eta$ be the learning rate (default $0.001$).\n",
    "\n",
    "### 1. Initialize\n",
    "- $m_0 = 0$ (vector of zeros)\n",
    "- $v_0 = 0$ (vector of zeros)\n",
    "\n",
    "### 2. Update Biased First and Second Moment Estimates\n",
    "\n",
    "$$\n",
    "m_t = \\beta_1 m_{t-1} + (1 - \\beta_1) g_t\n",
    "$$\n",
    "\n",
    "$$\n",
    "v_t = \\beta_2 v_{t-1} + (1 - \\beta_2) g_t^2\n",
    "$$\n",
    "\n",
    "- $m_t$: Exponentially decaying average of past gradients (first moment).\n",
    "- $v_t$: Exponentially decaying average of past squared gradients (second moment).\n",
    "\n",
    "### 3. Compute Bias-Corrected Estimates\n",
    "\n",
    "$$\n",
    "\\hat{m}_t = \\frac{m_t}{1 - \\beta_1^t}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t}\n",
    "$$\n",
    "\n",
    "- $\\hat{m}_t$: Bias-corrected first moment estimate.\n",
    "- $\\hat{v}_t$: Bias-corrected second moment estimate.\n",
    "\n",
    "### 4. Parameter Update\n",
    "\n",
    "$$\n",
    "\\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{\\hat{v}_t} + \\epsilon} \\hat{m}_t\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Step-by-Step Breakdown\n",
    "1. **Compute the gradient** $g_t$ for the current mini-batch.\n",
    "2. **Update first moment estimate:**\n",
    "   $$\n",
    "   m_t = \\beta_1 m_{t-1} + (1-\\beta_1) g_t\n",
    "   $$\n",
    "3. **Update second moment estimate:**\n",
    "   $$\n",
    "   v_t = \\beta_2 v_{t-1} + (1-\\beta_2) g_t^2\n",
    "   $$\n",
    "4. **Compute bias-corrected estimates:**\n",
    "   $$\n",
    "   \\hat{m}_t = \\frac{m_t}{1 - \\beta_1^t}\n",
    "   $$\n",
    "   $$\n",
    "   \\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t}\n",
    "   $$\n",
    "5. **Update parameters:**\n",
    "   $$\n",
    "   \\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{\\hat{v}_t} + \\epsilon} \\hat{m}_t\n",
    "   $$\n",
    "\n",
    "---\n",
    "\n",
    "## Explanation of Terms\n",
    "- **$\\beta_1$ (First Moment Decay Rate):** Controls the memory of the mean of gradients. Typical value: $0.9$.\n",
    "- **$\\beta_2$ (Second Moment Decay Rate):** Controls the memory of the uncentered variance of gradients. Typical value: $0.999$.\n",
    "- **$m_t$:** Exponentially decaying average of past gradients (momentum).\n",
    "- **$v_t$:** Exponentially decaying average of past squared gradients (RMSProp-like behavior).\n",
    "- **$\\hat{m}_t$, $\\hat{v}_t$:** Bias-corrected versions of $m_t$ and $v_t$.\n",
    "- **$\\epsilon$:** Prevents division by zero and stabilizes the update.\n",
    "- **$\\eta$:** Learning rate.\n",
    "\n",
    "---\n",
    "\n",
    "## Graphical Representation\n",
    "\n",
    "### 1. First and Second Moment Estimates\n",
    "A plot of $m_t$ and $v_t$ (y-axis) vs. time step $t$ (x-axis) shows how the running averages adapt to the gradient's magnitude and variance.\n",
    "\n",
    "### 2. Adaptive Update Step\n",
    "A plot of the effective update $\\frac{\\eta}{\\sqrt{\\hat{v}_t} + \\epsilon} \\hat{m}_t$ (y-axis) vs. time step $t$ (x-axis) shows how Adam adapts the step size for each parameter.\n",
    "\n",
    "```\n",
    "Graph 1: First and Second Moment Estimates (m_t, v_t)\n",
    "|\n",
    "|   /\\\n",
    "|  /  \\\n",
    "|_/____\\______ t\n",
    "\n",
    "Graph 2: Adaptive Update Step\n",
    "|\n",
    "|  /\\    /\\\n",
    "| /  \\__/  \\\n",
    "|/         \\____ t\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Advantages\n",
    "- **Combines benefits of AdaGrad and RMSProp.**\n",
    "- **Works well in practice for most deep learning problems.**\n",
    "- **Bias correction improves performance, especially in early training.**\n",
    "\n",
    "## Disadvantages\n",
    "- **Requires tuning of $\\eta$, $\\beta_1$, $\\beta_2$, and $\\epsilon$.**\n",
    "- **Can sometimes lead to non-convergent or unstable training if not tuned properly.**\n",
    "\n",
    "---\n",
    "\n",
    "## Summary Table\n",
    "| Step | Formula |\n",
    "|------|---------|\n",
    "| First Moment | $m_t = \\beta_1 m_{t-1} + (1-\\beta_1) g_t$ |\n",
    "| Second Moment | $v_t = \\beta_2 v_{t-1} + (1-\\beta_2) g_t^2$ |\n",
    "| Bias Correction | $\\hat{m}_t = \\frac{m_t}{1-\\beta_1^t}$, $\\hat{v}_t = \\frac{v_t}{1-\\beta_2^t}$ |\n",
    "| Parameter Update | $\\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{\\hat{v}_t} + \\epsilon} \\hat{m}_t$ |\n",
    "\n",
    "---\n",
    "\n",
    "If you want a code example or matplotlib graph for Adam, let me know!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
