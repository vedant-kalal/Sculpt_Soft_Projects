{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18dfea5c",
   "metadata": {},
   "source": [
    "# Deep Learning Core Concepts: Epochs, Learning Rate, Parameters, Hyperparameters, and Cost Function\n",
    "\n",
    "---\n",
    "\n",
    "## Epochs\n",
    "\n",
    "An **epoch** is one complete pass through the entire training dataset by the learning algorithm. If you have 10,000 training samples, one epoch means the network has seen all 10,000 samples once. Training usually requires multiple epochs to adjust the weights properly.\n",
    "\n",
    "- **Batch:** Subset of training data used for one update of the network.\n",
    "- **Iteration:** One update of the model’s weights using a batch.\n",
    "\n",
    "**Formula:**\n",
    "- Iterations per epoch:\n",
    "  $$\n",
    "  \\text{Iterations per epoch} = \\frac{\\text{Total samples}}{\\text{Batch size}}\n",
    "  $$\n",
    "- Total iterations:\n",
    "  $$\n",
    "  \\text{Total Iterations} = \\frac{\\text{Number of samples}}{\\text{Batch size}} \\times \\text{Epochs}\n",
    "  $$\n",
    "\n",
    "**Example:**\n",
    "- Training samples = 10,000\n",
    "- Batch size = 100\n",
    "- Iterations per epoch = 10,000 / 100 = 100\n",
    "- 20 epochs = 2,000 total iterations\n",
    "\n",
    "**Why Multiple Epochs?**\n",
    "- A single pass (1 epoch) is usually not enough for the model to learn properly.\n",
    "- Multiple passes allow the model to gradually adjust weights using backpropagation.\n",
    "- Too few epochs → underfitting; too many epochs → overfitting.\n",
    "\n",
    "**Weight Update per Epoch (Gradient Descent):**\n",
    "1. Compute predicted output:\n",
    "   $$\n",
    "   \\hat{y} = f(X, W)\n",
    "   $$\n",
    "2. Compute loss:\n",
    "   $$\n",
    "   L = \\text{Loss}(y, \\hat{y})\n",
    "   $$\n",
    "3. Compute gradients:\n",
    "   $$\n",
    "   \\frac{\\partial L}{\\partial W}\n",
    "   $$\n",
    "4. Update weights:\n",
    "   $$\n",
    "   W := W - \\eta \\frac{\\partial L}{\\partial W}\n",
    "   $$\n",
    "   where $\\eta$ is the learning rate.\n",
    "\n",
    "**Summary Table:**\n",
    "| Term      | Meaning                                  |\n",
    "|-----------|------------------------------------------|\n",
    "| Epoch     | One full pass through the dataset        |\n",
    "| Batch     | Subset of dataset for one weight update  |\n",
    "| Iteration | One update of weights (one batch)        |\n",
    "| Relation  | Iterations = (Samples / Batch) × Epochs  |\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Rate\n",
    "\n",
    "The **learning rate** ($\\eta$ or $\\alpha$) is a hyperparameter that controls how much we adjust the model’s weights during training. It determines the step size in the direction of the negative gradient.\n",
    "\n",
    "**Weight Update Rule:**\n",
    "$$\n",
    "W := W - \\eta \\frac{\\partial L}{\\partial W}\n",
    "$$\n",
    "\n",
    "- Too high: may overshoot the minimum of the loss function (unstable training).\n",
    "- Too low: training will be slow and may get stuck in local minima.\n",
    "\n",
    "**Example:**\n",
    "- Weight = 2\n",
    "- Gradient = 0.5\n",
    "- Learning rate = 0.1\n",
    "- Update: $W_{new} = 2 - 0.1 \\times 0.5 = 1.95$\n",
    "\n",
    "**Learning Rate Strategies:**\n",
    "- Fixed LR: Keep $\\eta$ constant.\n",
    "- Step Decay: Reduce $\\eta$ after some epochs.\n",
    "- Exponential Decay: $\\eta = \\eta_0 e^{-kt}$\n",
    "- Adaptive Optimizers: Adam, RMSProp, etc. adjust $\\eta$ per weight.\n",
    "\n",
    "**Summary:**\n",
    "- Learning rate = “step size” in gradient descent.\n",
    "- Too high → overshoot, unstable. Too low → slow.\n",
    "- Typical starting values: 0.001 – 0.01\n",
    "\n",
    "---\n",
    "\n",
    "## Parameters vs Hyperparameters\n",
    "\n",
    "### Parameters\n",
    "- Internal variables of a model learned from the training data.\n",
    "- Define the behavior of the model.\n",
    "- Updated automatically during training (e.g., weights, biases).\n",
    "\n",
    "**Example:**\n",
    "- Linear Regression: $y = Wx + b$ ($W$ and $b$ are parameters)\n",
    "- Neural Network: All weights and biases in each layer\n",
    "\n",
    "### Hyperparameters\n",
    "- External configurations set before training.\n",
    "- Not learned from the data.\n",
    "- Control how the model is trained (e.g., learning rate, batch size, number of epochs, number of layers, regularization parameter $\\lambda$).\n",
    "\n",
    "**Example:**\n",
    "- Learning rate = 0.001\n",
    "- Epochs = 50\n",
    "- Batch size = 64\n",
    "- Number of hidden layers = 3\n",
    "\n",
    "**Table Summary:**\n",
    "| Feature        | Parameter                        | Hyperparameter                      |\n",
    "|----------------|----------------------------------|-------------------------------------|\n",
    "| Definition     | Learned by the model from data   | Set before training, controls train |\n",
    "| Updated by     | Training algorithm               | Not updated during training         |\n",
    "| Examples       | Weights, biases                  | Learning rate, batch size, layers   |\n",
    "| Role           | Defines model’s prediction       | Defines how model learns            |\n",
    "| Determined by  | Data                             | User or search/tuning               |\n",
    "\n",
    "**Intuition:**\n",
    "- Parameters = the answers the model finds\n",
    "- Hyperparameters = the rules that guide how the model finds answers\n",
    "\n",
    "---\n",
    "\n",
    "## Cost Function (Loss Function)\n",
    "\n",
    "A **Cost Function** (or Loss Function) is a mathematical function that measures how “bad” the model is at making predictions. It quantifies the difference between the model’s predictions and the actual target values. The goal of training is to minimize the cost function by adjusting the model’s parameters.\n",
    "\n",
    "**Why is it important?**\n",
    "- Guides the learning: tells the algorithm whether to increase or decrease weights.\n",
    "- Smaller cost → better model; larger cost → worse predictions.\n",
    "\n",
    "### Common Cost Functions\n",
    "\n",
    "#### a) Mean Squared Error (MSE) — Regression\n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "- $y_i$ = actual value\n",
    "- $\\hat{y}_i$ = predicted value\n",
    "- $n$ = number of samples\n",
    "\n",
    "#### b) Cross-Entropy Loss — Classification\n",
    "$$\n",
    "L = -\\sum_i y_i \\log(\\hat{y}_i)\n",
    "$$\n",
    "- $y_i$ = 1 if class is correct, 0 otherwise (one-hot encoding)\n",
    "- $\\hat{y}_i$ = predicted probability for that class (Softmax output)\n",
    "\n",
    "**How it Works in Training:**\n",
    "1. Model predicts output $\\hat{y}$\n",
    "2. Compute cost $L$ (compare with true $y$)\n",
    "3. Use gradient descent to update weights to reduce cost:\n",
    "   $$\n",
    "   W := W - \\eta \\frac{\\partial L}{\\partial W}\n",
    "   $$\n",
    "\n",
    "**Intuition:**\n",
    "- Cost function = “score” of the model\n",
    "- Lower score → better predictions\n",
    "- Determines direction of weight updates\n",
    "\n",
    "**Example:**\n",
    "- MSE: Actual = [2, 3], Predicted = [2.5, 2.0]\n",
    "  $$\n",
    "  \\text{MSE} = \\frac{(2-2.5)^2 + (3-2)^2}{2} = \\frac{0.25 + 1}{2} = 0.625\n",
    "  $$\n",
    "\n",
    "**Summary:**\n",
    "- Cost Function = error calculator\n",
    "- Guides how the model learns\n",
    "- Examples: MSE (regression), Cross-Entropy (classification)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
